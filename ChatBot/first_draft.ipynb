{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ec931",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatOpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=os.getenv(\"OPENROUTER_DEEPSEEK_API_KEY\"),  # or hardcode for now\n",
    "            model=\"deepseek/deepseek-chat\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import add_messages #is a reducer similar to add  but for \n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], \"List of chat messages\",add_messages]\n",
    "    user_id: Annotated[str, \"Unique identifier for the user\"]\n",
    "    chat_id: Annotated[str, \"Unique identifier for the chat session\"]\n",
    "    context: Annotated[dict[str, str], \"Contextual information for the chat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "    messages=state['messages']\n",
    "    response=model.invoke(messages)\n",
    "    return {'messages': {response}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c03855",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer=MemorySaver()\n",
    "graph=StateGraph(ChatState)\n",
    "graph.add_node(chat_node,'chat_node')\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_edge('chat_node', END)\n",
    "\n",
    "chatbot= graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3952d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state={\n",
    "    'messages': [HumanMessage(content=\"Hello\")],\n",
    "    'user_id': 'user-123',\n",
    "    'chat_id': 'chat-456',\n",
    "    'context': {}\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86421802",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id='1'\n",
    "while True:\n",
    "    user_message=input(\"Your message here: \")\n",
    "    print('You: ', user_message)\n",
    "    if user_message.lower() in ['exit', 'quit']:\n",
    "        break\n",
    "    config={'configurable':{'thread_id':thread_id}}\n",
    "    response=chatbot.invoke({'messages':[HumanMessage(content=user_message)]},config=config)\n",
    "    print(\"Chatbot response:\", response['messages'][-1].content)\n",
    "   # Assuming the last message is the bot's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c85653",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.get_state(config=config)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
